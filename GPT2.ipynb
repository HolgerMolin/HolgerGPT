{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HolgerMolin/HolgerGPT/blob/main/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn import init\n",
    "import random\n",
    "import numpy as np\n",
    "from tokenizer import Tokenizer\n",
    "from architecture import HolgerGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqdQNipKZLyS"
   },
   "source": [
    "TODO:\n",
    "    - RMS norm\n",
    "    - Spicy attention\n",
    "    - GeLU\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 1_115_394\n",
      "['\\n', ' ', '!', '#', '$', '&', \"'\", '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "dataset = open('tokenizer_training.txt').read().lower()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vocab = sorted(list(set(dataset)))\n",
    "dataset = open('training.txt').read().lower()\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "tokenizer = Tokenizer(vocab)\n",
    "dataset = tokenizer.encode(dataset)\n",
    "tokenizer.train(dataset, vocab_size - len(vocab))\n",
    "text_length = len(dataset)\n",
    "print(f'Number of tokens: {text_length:_}')\n",
    "print(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 200_502\n"
     ]
    }
   ],
   "source": [
    "context_length = 32\n",
    "model = HolgerGPT(3, 64, 2, 64, context_length, vocab_size)\n",
    "print(f'Number of parameters: {sum(p.numel() for p in model.parameters()):_}')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "class TransformerLRScheduler:\n",
    "    def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.step_num = 1\n",
    "\n",
    "    def step(self):\n",
    "        self.step_num += 1\n",
    "        lr = self._get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _get_lr(self):\n",
    "        arg1 = self.step_num ** -0.5\n",
    "        arg2 = self.step_num * (self.warmup_steps ** -1.5)\n",
    "        return (self.d_model ** -0.5) * min(arg1, arg2)\n",
    "\n",
    "scheduler = TransformerLRScheduler(optim, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transformer_block in model.transformer_blocks:\n",
    "    for attention_head in transformer_block.attention.heads:\n",
    "        attention_head.w_k = attention_head.w_k.to(device)\n",
    "        attention_head.w_q = attention_head.w_q.to(device)\n",
    "        attention_head.mask = attention_head.mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRETRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.080578 2.470529e-07\n",
      "51 3.860074 1.259970e-05\n",
      "101 3.307584 2.495235e-05\n",
      "151 3.026561 3.730499e-05\n",
      "201 2.983659 4.965764e-05\n",
      "251 2.971040 6.201029e-05\n",
      "301 2.957855 7.436294e-05\n",
      "351 2.941096 8.671558e-05\n",
      "401 2.889591 9.906823e-05\n",
      "451 2.822158 1.114209e-04\n",
      "501 2.698100 1.237735e-04\n",
      "551 2.581423 1.361262e-04\n",
      "601 2.520832 1.484788e-04\n",
      "651 2.448850 1.608315e-04\n",
      "701 2.383521 1.731841e-04\n",
      "751 2.350719 1.855368e-04\n",
      "801 2.323594 1.978894e-04\n",
      "851 2.294322 2.102421e-04\n",
      "901 2.265074 2.225947e-04\n",
      "951 2.249390 2.349473e-04\n",
      "1001 2.227370 2.473000e-04\n",
      "1051 2.168285 2.596526e-04\n",
      "1101 2.142169 2.720053e-04\n",
      "1151 2.157745 2.843579e-04\n",
      "1201 2.103859 2.967106e-04\n",
      "1251 2.115675 3.090632e-04\n",
      "1301 2.088366 3.214159e-04\n",
      "1351 2.083470 3.337685e-04\n",
      "1401 2.054857 3.461212e-04\n",
      "1451 2.036747 3.584738e-04\n",
      "1501 2.031680 3.708265e-04\n"
     ]
    }
   ],
   "source": [
    "dataset = open('ptbdataset/ptb.train.txt').read().lower()\n",
    "dataset = tokenizer.encode(dataset)\n",
    "text_length = len(dataset)\n",
    "\n",
    "max_index = text_length - context_length - 1\n",
    "num_steps = 20_000\n",
    "batch_size = 256\n",
    "display_frequency = 50\n",
    "period_loss = 0\n",
    "start_indices = np.random.randint(0, max_index, size=(num_steps, batch_size))\n",
    "for step in range(num_steps):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    x = [dataset[start_idx: start_idx + context_length] for start_idx in start_indices[step]]\n",
    "    x = torch.tensor(x)\n",
    "    y_true = [dataset[start_idx + context_length] for start_idx in start_indices[step]]\n",
    "    y_true = torch.tensor(y_true)\n",
    "\n",
    "    y_pred = model.forward(x)\n",
    "    loss = criterion(y_pred, y_true)\n",
    "    period_loss += loss.item()\n",
    "    \n",
    "    loss.backward()\n",
    "    if step % display_frequency == 0:\n",
    "        print(f'{scheduler.step_num} {period_loss/display_frequency:4f} {scheduler._get_lr():4e}')\n",
    "        period_loss = 0\n",
    "    optim.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[:context_length]\n",
    "indices = list(sample_text)\n",
    "output = []\n",
    "for _ in range(500):\n",
    "    x = torch.tensor(indices).reshape(1, -1).to(device)\n",
    "    y = model.forward(x)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    y = torch.multinomial(y, 1)\n",
    "    y = y.item()\n",
    "    indices.pop(0)\n",
    "    indices.append(y)\n",
    "    output.append(y)\n",
    "    \n",
    "print(''.join(tokenizer.decode(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[:context_length]\n",
    "indices = list(sample_text)\n",
    "output = []\n",
    "for _ in range(500):\n",
    "    x = torch.tensor(indices).reshape(1, -1).to(device)\n",
    "    y = model.forward(x)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    y = torch.multinomial(y, 1)\n",
    "    y = y.item()\n",
    "    indices.pop(0)\n",
    "    indices.append(y)\n",
    "    output.append(y)\n",
    "    \n",
    "print(''.join(tokenizer.decode(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'intermediate_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyODYauqXomLi5jwEeU5Z0G8",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
